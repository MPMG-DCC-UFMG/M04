########################################################################
Programa Capacidades Analíticas (PCA) - MP || UFMG
Mineração de Grafos como suporte para construção de trilhas (M04)
PIPELINE: Módulo para persistência dos dados no hive.
Desenvolvido por: Pedro Rodrigues, e-mail:pedro.henrique.riopira@gmail.com 
########################################################################

** O objetivo deste módulo é receber dados no formato .csv e realizar a **
** inserção destes em tabelas pré-definidas no Apache Hive. Para tal,   **
** deve-se utilizar comandos de linha para interagir com o script que   **
** realiza a inserção, abaixo estão as regras do comando de linha e as  **
** possíveis interações:						**
**									**
**	-h  :  Veja as opções do script.				**
**	-f  :  Endereço do arquivo a ser gravado no padrão: 		**
**	        'diretorio1/diretorio2/arquivo.csv'.			**
**	-bs :  Define a quantidade de dados gravados por batch, o 	**
**		padrão é 100.						**
**	-i  :  Quantidade de gravações realizadas, o padrão é até o 	**
**		arquivo terminar.					**
**	-d  :  Seguido de 'n' remove o campo de data do final, há um	**
**		campo de data pré-definido no final das inserções.	**
**	-p  :  Se trata do formato (pattern) das colunas da tabela, é	**
**		 preciso utilizar as palavras-chave id, int, str,	**
**		 float, ou date para que o script faça a inserção 	**
**		 corretamente, utilizando / como separador. 		**
**		 Por exemplo: id/str/int/date para uma tabela com	**
**		 colunas de id/string/numero/data.			**
**	-id :  Define o id (número) em que se deve começar a inserção.  **
**	-c  :  Define uma linha do arquivo em que o script deve		**
**		começar (ou continuar) a inserção, em caso de inserção  **
**		com index ele continua a inserção a partir do index da	**
**		linha do arquivo.					**
**									**
** Um detalhe importante é sobre como o programa define os nomes dos	**
** cabeçalhos e tabelas para realização das queries, para tal um	**
** arquivo chamado cabecalhosTradutor.json é responsável por ligar nome **
** do arquivo final (csv) com uma tabela e suas colunas, então é	**
** preciso mapear as tabelas antes de rodar o script.			**
**   									**
** O arquivo conexaoConfiguracao.json trata da conexão com o banco.	**
**
** A pasta log_falhos armazena as linhas de um arquivo em que a query	**
** não foi realizada por qualquer motivo (100 linhas adicionais finais  **
** sempre serão geradas no arquivo, favor desconsiderá-las).		**
**									**
** Exemplo de comando de linha:						**
**									**
** python3 main.py -f /dados01/workspace/ufmg_2021_m04/pipeline_08_2022/**
** M04/M04-pipeline/fraud-detection-module/output/			**
** rank-cross-graph-quasi-cliques.csv -bs 1000 -p id/str/str/float/date	**
**  -d s -id 1								**
**									**
** O comando acima pega os dados em rank-cross-graph-quasi-cliques.csv  **
** e os insere no banco do hive (mapeado no cabecalhosTradutor.json)	**
** até o arquivo terminar de batches de 1000 em 1000 dados por query	**
** inserção. A inserção considera que a primeira coluna é um id, a	**
** segundo e terceira são strings, a quarta é um float e por último uma **
** data. Além disso, "-d s" liga o acionamento da data disponibilizada  **
** pelo script na hora da inserção. O id inicial de inserção (primeira  **
** coluna) será 1.							**

######################################################################
